/home/xxproject/lib
tar -xzvf apache-hive-2.1.1-bin.tar.gz
ln -sf apache-hive-2.1.1-bin hive

echo '
# !!!No Modification, This Section is Auto Generated by Hive
export HIVE_HOME=/home/xxproject/lib/hive
export PATH=${PATH}:${HIVE_HOME}/bin
' >> ~/.bash_profile
source ~/.bash_profile

安装mysql
sudo yum install mysql-server -y
sudo vi /etc/my.cnf

# !!!Edit By MySQL
bind-address		= 0.0.0.0
default-storage-engine = innodb
innodb_file_per_table
collation-server = utf8_general_ci
init-connect = 'SET NAMES utf8'
character-set-server = utf8
# !!!Edit By MySQL

sudo service mysqld restart

export MYSQL_ROOT_PASSWORD="root"
export MYSQL_DATABASE="db_hive"
export MYSQL_USER="test"
export MYSQL_PASSWORD="test"


mysql -uroot -e "grant all privileges on *.* to 'root'@'%' identified by '${MYSQL_ROOT_PASSWORD}';"
mysql -uroot -e "grant all privileges on *.* to 'root'@'localhost' identified by '${MYSQL_ROOT_PASSWORD}';"
mysql -uroot -p"${MYSQL_ROOT_PASSWORD}" -e "CREATE DATABASE ${MYSQL_DATABASE};"
mysql -uroot -p"${MYSQL_ROOT_PASSWORD}" -e "grant all privileges on *.* to '${MYSQL_USER}'@'%' identified by '${MYSQL_PASSWORD}';"
mysql -uroot -p"${MYSQL_ROOT_PASSWORD}" -e "grant all privileges on *.* to '${MYSQL_USER}'@'localhost' identified by '${MYSQL_PASSWORD}';"

sudo service mysqld restart

mkdir -p /home/xxproject/data/hive

修改 hive.xml 以下几个选项： 
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <!-- <value>jdbc:mysql://weekend01:3306/hive?createDatabaseIfNotExist=true</value> -->
        <value>jdbc:mysql://localhost:3306/db_hive?createDatabaseIfNotExist=true</value>
        <description>JDBC connect string for a JDBC metastore</description>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.jdbc.Driver</value>
        <description>Driver class name for a JDBC metastore</description>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>test</value>
        <description>username to use against metastore database</description>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>test</value>
        <description>password to use against metastore database</description>
    </property>

    <property>
    <name>hive.querylog.location</name>
    <value>/home/xxproject/data/hive/${system:user.name}</value>
    <description>Location of Hive run time structured log file</description>
  </property>
  <property>
    <name>hive.server2.logging.operation.log.location</name>
    <value>/home/xxproject/data/hive/${system:user.name}/operation_logs</value>
    <description>Top level directory where operation logs are stored if logging functionality is enabled</description>
  </property>
  <property>
    <name>hive.exec.local.scratchdir</name>
    <value>/home/xxproject/data/hive/${system:user.name}</value>
    <description>Local scratch space for Hive jobs</description>
  </property>
  <property>
    <name>hive.downloaded.resources.dir</name>
    <value>/home/xxproject/data/hive/${hive.session.id}_resources</value>
    <description>Temporary local directory for added resources in the remote file system.</description>
  </property>
  

拷贝MySQL驱动到HIVE的lib目录: mysql-connector-java-5.1.44.jar

元数据初始化: schematool -initSchema -dbType mysql

schematool -initSchema -dbType mysql




测试一下--MANAGED_TABLE（数据默认在 /user/hive/warehouse/db_order.db/tbl_order 下面）:
create database db_order;
use db_order;
////////////////////////////////////////////////////////////////////////////////////////////////////////
create table tbl_order(id int, name string, size string, price double)
row format delimited
fields terminated by '\t';
////////////////////////////////////////////////////////////////////////////////////////////////////////
load data local inpath '/home/xxproject/order.txt' into table tbl_order;
手动直接上传:
hadoop fs -put order.txt /user/hive/warehouse/db_order.db/tbl_order/order.txt.put
////////////////////////////////////////////////////////////////////////////////////////////////////////
select * from tbl_order;
select count(*) from tbl_order;
select name, sum(price) from tbl_order group by name;

测试一下--动态外部表--EXTERNAL_TABLE（数据位置随意放置）
hadoop fs -mkdir -p /ordertest/
hadoop fs -put order.txt /ordertest/

create external table tbl_order_ext(id int, name string, size string, price double)
row format delimited
fields terminated by '\t'
location '/ordertest/';

select * from tbl_order_ext;

屌不屌？？？

测试一下----临时表（相当于MR中间结果）：
create table tbl_order_ctas
as
select id,name,price from tbl_order;
////////////////////////////////////////////////////////////////////////////////////////////////////////
select * from tbl_order_ctas;


测试一下----分区---与MySQL类似-----查询时WHERE带分区标志：
create table tbl_order_pt(id int, name string, size string, price double)
partitioned by (month string)
row format delimited
fields terminated by '\t';
////////////////////////////////////////////////////////////////////////////////////////////////////////
load data local inpath 'order_new.txt' into table tbl_order_pt partition(month='201601');
load data local inpath 'order_broken.txt' into table tbl_order_pt partition(month='201602');
show partitions tbl_order_pt;
////////////////////////////////////////////////////////////////////////////////////////////////////////
select * from tbl_order_pt where month='201602';



测试一下----UDF
hadoop fs -mkdir -p /udttest/
hadoop fs -put udt.test.txt /udttest/

add jar hive.jar
create temporary function areax as com.xcompany.xproject.hive.Phone2Area;

create external table tbl_udf_ext(phone string, url string)
row format delimited
fields terminated by ','
location '/udttest/';

select * from tbl_udf_ext;
select phone, areax(phone) from tbl_udf_ext;


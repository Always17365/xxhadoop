Spark参考博客：http://blog.csdn.net/lovehuangjiaju

版本：2.2.0
#Pre-build with user-provided Hadoop: "Hadoop free" 版，可应用到任意 Hadoop 版本
#https://www.apache.org/dyn/closer.lua/spark/spark-2.2.0/spark-2.2.0-bin-without-hadoop.tgz

Pre-built for Apache Hadoop 2.7 and later 
https://www.apache.org/dyn/closer.lua/spark/spark-2.2.0/spark-2.2.0-bin-hadoop2.7.tgz


安装Java==1.8.0_144、Scala==2.11.11
tar -xzvf spark-2.2.0-bin-hadoop2.7.tgz
ln -sf spark-2.2.0-bin-hadoop2.7 spark

配置环境变量
echo '
# !!!No Modification, This Section is Auto Generated by Spark
export SPARK_HOME=/home/xxproject/lib/spark
export PATH=${PATH}:${SPARK_HOME}/bin
' >> ~/.bash_profile
source ~/.bash_profile

配置slaves节点
cd spark/conf/
cp slaves.template slaves
vi slaves

# localhost
node-01
node-02
node-03
node-04

配置spark启动环境变量
cp spark-env.sh.template spark-env.sh
vi spark-env.sh

export JAVA_HOME=/home/xxproject/lib/jdk
# export SCALA_HOME=/home/xxproject/lib/scala
export SPARK_MASTER_HOST=node-01
export SPARK_MASTER_PORT=7077
# export MASTER=spark://${SPARK_MASTER_HOST}:${SPARK_MASTER_PORT}
export SPARK_WORKER_CORES=1
# export SPARK_WORKER_INSTANCES=1
export SPARK_WORKER_MEMORY=1g
# export HADOOP_CONF_DIR=/opt/hadoop-2.7.3/etc/hadoop
# export HADOOP_HOME=/home/hadoop/package/hadoop-2.7.2/etc/hadoop
# export SPARK_DIST_CLASSPATH=$(/usr/local/hadoop/bin/hadoop classpath)

启动spark集群：
sbin/start-all.sh


查看界面：http://10.20.0.11:8080/
测试一下：
cd /home/xxproject/lib/spark
spark-submit --class org.apache.spark.examples.SparkPi --master spark://node-01:7077 --executor-memory 1G --total-executor-cores 1 /home/xxproject/lib/spark/examples/jars/spark-examples_2.11-2.2.0.jar 100

spark-shell测试：
spark-shell --master spark://node-01:7077 --executor-memory 1G --total-executor-cores 1

val lines = sc.textFile("file:///home/xxproject/workspace/xxhadoop/spark_data/")
val words = lines.flatMap(line => line.split(" ") )
val wordCounts = words.map(word => (word, 1)).reduceByKey((a, b) => a + b)
wordCounts.collect().foreach(println)
wordCounts.partitions.length
wordCounts.saveAsTextFile("file:///tmp/output")





